---
layout: single
title: "9월 결산"
categories: 결산
tag: [이어드림스쿨, 결산]
toc: true
author_profile: false
search: true
---

## 한글날에 작성하는 9월 결산입니다.

<br/>

그동안의 커리큘럼

<img src="../../images/2022-10-10-9월결산/20221010first.png" alt="20221010first.png" style="zoom:100%;" />

<br/>

상세 시간표

<img src="../../images/2022-10-10-9월결산/20221010second.png" alt="20221010second.png" style="zoom:100%;" />

<br/>

## 기업연계 Final 프로젝트

9월5일부터 제가 이어드림 과정에서 가장 관심있게 지켜보고 있던 기업연계 프로젝트가 시작되었습니다. 이 프로젝트 이후에는 Kaggle 경진대회 참가가 남아있긴 하지만 저는 이번 프로젝트를 마친 뒤 입사지원을 하는게 목표이기 때문에 과정의 마무리라는 생각으로 임하고 있습니다.

운이 좋게도 이번 프로젝트도 좋은 팀원들과 한팀에 배정되었고 1지망으로 지원했던 기업과 연계 프로젝트를 진행하게 되었습니다.

함께 연계 프로젝트를 진행하게 된 기업은 영상제작 분야에 인공지능 기술을 접목시켜 텍스트 입력만으로 AI 아나운서 등 디지털 휴먼이 말을 하는 영상을 제작하여 영상 제작에 소요되는 시간과 비용을 줄여주는 사업을 진행중인 스타트업 기업입니다.

기업에서 제시한 과제는 아래 두 가지이며

- 수집된 데이터에 대해 사람이 일일이 눈으로 퀄리티를 판별하는 task를 자동화 하는 것
- 얼굴 이미지 퀄리티 판별에 있어 새롭게 내세울 수 있는 지표를 수립하는 것

이를 통해 저희가 최종적으로 도달하고자 하는 목표는 No-Reference 방식의 Image Quality Assessment Model을 개선하는 것입니다.

프로젝트 기획단계에서 부터 어떻게 풀어나갈지 막막했었는데 운영측에서 매칭해주신 멘토님께서 적극적으로 멘토링에 임해주셔서 어느정도는 갈피를 잡을 수 있었습니다.

멘토님께서는 ‘n사’에서 근무중이신 현업 연구직 이신데 평소에 자주 하시는 논문 review와 이를 바탕으로 한가지 모델을 정하고 그 모델을 개선시킬 수 있는 다른 module을 접목시켜 문제를 해결하는 방식으로 프로젝트를 진행하는게 어떻겠냐고 제안을 해주셨고 팀원들 모두 이에 동의하여 이런 방식으로 프로젝트를 진행하게 되었습니다.

우선, 기업에서 제시한 NR method IQA 모델을 5가지 살펴보고(팀원이 5명이라 멘토님께서 5가지 논문을 골라주셨습니다.) 각 모델들이 가진 한계점과 이를 어떻게 극복할지를 FIQA 논문들에서 찾아보기로 하였습니다.

<br/>

저희가 살펴본 논문들입니다.

NR IQA

- HyperIQA
  [](https://openaccess.thecvf.com/content_CVPR_2020/papers/Su_Blindly_Assess_Image_Quality_in_the_Wild_Guided_by_a_CVPR_2020_paper.pdf)
- TReS
  [No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency](https://arxiv.org/abs/2108.06858)
- MUSIQ
  [MUSIQ: Multi-scale Image Quality Transformer](https://arxiv.org/abs/2108.05997)
- MANIQA
  [MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment](https://arxiv.org/abs/2204.08958)
- MetaIQA
  [MetaIQA: Deep Meta-learning for No-Reference Image Quality Assessment](https://arxiv.org/abs/2004.05508)

최근 general image quality model들은 CNN에 transformer를 접목시켜 성능을 향상시키는 추세인것 같고 보통의 이미지에 대해서는 좋은 성능을 보여줬지만 얼굴만을 crop한 image에 대해서는 원본이미지에 비해 예측 성능이 상당히 떨어지는 모습을 보였습니다.

<br/>

그런다음, 얼굴 이미지 퀄리티 평가에 특화되어있는 논문들을 추가로 살펴보았습니다.

FIQA

- MagFace
  [](https://openaccess.thecvf.com/content/CVPR2021/papers/Meng_MagFace_A_Universal_Representation_for_Face_Recognition_and_Quality_Assessment_CVPR_2021_paper.pdf)
- SDD-FIQA
  [](https://openaccess.thecvf.com/content/CVPR2021/papers/Ou_SDD-FIQA_Unsupervised_Face_Image_Quality_Assessment_With_Similarity_Distribution_Distance_CVPR_2021_paper.pdf)
- SER-IQA
  [](https://arxiv.org/pdf/2003.09373v1.pdf)
- Face Image Quality Assessment: A Literature Survey
  [](https://arxiv.org/pdf/2009.01103.pdf)

저희가 해야하는 일은 기존의 mos를 대체할 지표를 찾고 이를 바탕으로 얼굴이미지에 대한 퀄리티 평가를 제대로 할 수 있도록 기존의 모델을 개선시키거나 새로운 모델을 만드는 것입니다.

위 FIQA 모델들은 들어온 dataset에서 사람 한명한명을 각각의 class로 받아 pseudo label을 만드는데, 저희는 이 pseudo label을 mos값 대신 사용하기로 하였습니다.

pseudo label 점수를 사용하기에 앞서 검증이 필요했기 때문에 저희는 mos값이 labeling되어있는 dataset을 가지고 해당 모델에 넣어보고, 나온 predict 점수를 mos와 비교하기로 하였습니다.

하지만 pseudo label은 mos와 유사도가 떨어졌고 얼굴부분만 crop할 경우 더 욱 낮은 유사도를 보여주었습니다.

또, FIQA 모델들은 일단 얼굴이 recognition 되기만 하면 일단 괜찮은 점수를 부여하는 양상을 보여주어 사람의 눈으로 보았을 때 distortion이 많이 들어간 이미지라고 해도 얼굴만 인식된다면 높은 점수를 부여하였습니다. 그리고 얼굴이미지의 각도별로 model이 인식하기에 눈이나 코, 입이 있어야 하는 위치에 해당 부위가 인식되지 않는 사진이면(예-고화질의 옆면 사진) 점수를 낮게 부여하는 특징이 있었습니다.

이런 특징들로 부터 오는 성능 저하를 극복하기 위해 저희가 구상한 방안은 general한 IQA 모델로 이미지 품질을 판별한 뒤 MagFace와 같은 FIQA 모델을 통해 얼굴의 각도까지 판별하여 점수를 합산하는 구조를 만드는 것입니다.

최종적으로는 이미지 해상도에 따라 점수 구분이 되어야 하며 거기에 얼굴 각도에 따라 점수가 달라지도록 하는것이 목표입니다.

---

그리고 위와 같은 과정에서 개인적으로 살펴본 논문도 한편 있습니다.

- FaceQgen
  [](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/cd01cdfc-39e7-49ec-9889-7a7bb489ddff/2201.00770.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T061315Z&X-Amz-Expires=86400&X-Amz-Signature=581e62ca54149366ddb6985b2114db6b8c40513182c6c3188827b437d1886b32&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%222201.00770.pdf%22&x-id=GetObject)

이 모델은 반지도학습 방식으로 훈련을 위해 label이 필요없으며,

품질을 알 수 없는 이미지에 정면포즈, 균일한 배경 등의 이미지 복원을 적용해 고품질의 이미지로 변환하여 원본과 복원된 이미지의 유사도를 통해 품질평가가 이루어지는 방식의 모델입니다.

해당 모델은 저희가 하는 프로젝트에 굉장히 적합한 해결책으로 보이지만 구현된 코드에 train 코드가 없고 굉장히 간단하게만 작성되어있어 저희 입맛에 맞게 필요하다고 생각되는 module을 접목시킨다거나 다른 데이터셋으로 학습을 시켜본다거나 하는 실험과정을 거치기 힘들다고 판단되어 조금 더 연구가 필요할 것으로 보입니다.

---

이제 최종발표까지 2주 정도밖에 남지 않은 상황입니다.

결과물을 만들어 내는것도 중요하지만 그 과정에서 팀원들 모두 해보고싶은 실험과 가설 검증등을 통해 성장하는 것을 가장 중요하게 생각하며 시작한 프로젝트 이기에 프로젝트가 끝나는 날까지 여러가지를 해볼 생각입니다.

가끔 길을 잃을 때도 있지만 좋은 팀원들과 머리를 맞대고 집단지성의 힘으로 극복해보겠습니다.
